{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Machine Learning with Scikit-Learn & TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 9 Up and Running with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Graph to be evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a TensorFlow session to evaluate the Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Session that autometically sets itself as the default session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x107d01828>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x115194c50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset default graph to avoid duplicate nodes when experimenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) #evaluates w, then x, then y\n",
    "    print(z.eval()) #evaluates w, then x, then z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make TensorFlow to evaluate both y and z in  one graph run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Linear Regression using the Normal Equation to evaluate theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.74651413e+01],\n",
       "       [  4.35734153e-01],\n",
       "       [  9.33829229e-03],\n",
       "       [ -1.06622010e-01],\n",
       "       [  6.44106984e-01],\n",
       "       [ -4.25131839e-06],\n",
       "       [ -3.77322501e-03],\n",
       "       [ -4.26648885e-01],\n",
       "       [ -4.40514028e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Computing the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m,n = housing.data.shape\n",
    "ss = StandardScaler()\n",
    "ss_housing = ss.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m,1)), ss_housing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 10.3409\n",
      "Epoch 100 MSE = 0.729504\n",
      "Epoch 200 MSE = 0.573306\n",
      "Epoch 300 MSE = 0.557988\n",
      "Epoch 400 MSE = 0.548578\n",
      "Epoch 500 MSE = 0.541818\n",
      "Epoch 600 MSE = 0.536942\n",
      "Epoch 700 MSE = 0.533426\n",
      "Epoch 800 MSE = 0.530889\n",
      "Epoch 900 MSE = 0.529058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.06855249e+00],\n",
       "       [  7.96586573e-01],\n",
       "       [  1.35625824e-01],\n",
       "       [ -1.59971863e-01],\n",
       "       [  1.99437290e-01],\n",
       "       [  2.06436077e-03],\n",
       "       [ -4.00493890e-02],\n",
       "       [ -8.07897389e-01],\n",
       "       [ -7.72620857e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "#XT = tf.transpose(X)\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m*tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 14.9569\n",
      "Epoch 100 MSE = 0.902462\n",
      "Epoch 200 MSE = 0.652097\n",
      "Epoch 300 MSE = 0.619159\n",
      "Epoch 400 MSE = 0.597214\n",
      "Epoch 500 MSE = 0.580691\n",
      "Epoch 600 MSE = 0.568143\n",
      "Epoch 700 MSE = 0.558565\n",
      "Epoch 800 MSE = 0.551217\n",
      "Epoch 900 MSE = 0.54555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249],\n",
       "       [ 0.90658039],\n",
       "       [ 0.16214627],\n",
       "       [-0.35675687],\n",
       "       [ 0.35731012],\n",
       "       [ 0.01028404],\n",
       "       [-0.044638  ],\n",
       "       [-0.51127869],\n",
       "       [-0.48827058]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "#XT = tf.transpose(X)\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0] #2/m*tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.81987\n",
      "Epoch 100 MSE = 0.81702\n",
      "Epoch 200 MSE = 0.675491\n",
      "Epoch 300 MSE = 0.634579\n",
      "Epoch 400 MSE = 0.605852\n",
      "Epoch 500 MSE = 0.584823\n",
      "Epoch 600 MSE = 0.569374\n",
      "Epoch 700 MSE = 0.557995\n",
      "Epoch 800 MSE = 0.549591\n",
      "Epoch 900 MSE = 0.543365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249],\n",
       "       [ 0.85308784],\n",
       "       [ 0.16113423],\n",
       "       [-0.23882641],\n",
       "       [ 0.25237545],\n",
       "       [ 0.01061077],\n",
       "       [-0.04341198],\n",
       "       [-0.56889474],\n",
       "       [-0.53884482]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "#XT = tf.transpose(X)\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "#gradients = tf.gradients(mse, [theta])[0] #2/m*tf.matmul(tf.transpose(X), error)\n",
    "#training_op = tf.assign(theta, theta-learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_batch(epoch=None, batch_index=None, batch_size=None):\n",
    "    housing = fetch_california_housing()\n",
    "    m,n = housing.data.shape\n",
    "    ss = StandardScaler()\n",
    "    ss_housing = ss.fit_transform(housing.data)\n",
    "    scaled_housing_data_plus_bias = np.c_[np.ones((m,1)), ss_housing]\n",
    "    random.seed(epoch)\n",
    "    indices = np.arange(m)\n",
    "    #random.shuffle(indices)\n",
    "    #print(indices)\n",
    "    #start = batch_index*batch_size\n",
    "    #end = min(start+batch_size,m)\n",
    "    ids = np.random.choice(indices, batch_size, replace=False) # randomly choose a subset(size=batch_size)of the indices\n",
    "    X_batch = scaled_housing_data_plus_bias[ids] #[indices[start:end]]\n",
    "    y_batch = housing.target.reshape(-1,1)[ids] #[indices[start:end]]\n",
    "    return X_batch, y_batch #indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.87678\n",
      "Epoch 100 MSE = 0.538309\n",
      "Epoch 200 MSE = 0.515453\n",
      "Epoch 300 MSE = 0.491285\n",
      "Epoch 400 MSE = 0.551615\n",
      "Epoch 500 MSE = 0.564801\n",
      "Epoch 600 MSE = 0.545008\n",
      "Epoch 700 MSE = 0.493773\n",
      "Epoch 800 MSE = 0.530625\n",
      "Epoch 900 MSE = 0.450043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.06964231],\n",
       "       [ 0.83144158],\n",
       "       [ 0.11716183],\n",
       "       [-0.25468799],\n",
       "       [ 0.31521973],\n",
       "       [-0.00509178],\n",
       "       [-0.03455453],\n",
       "       [-0.90202737],\n",
       "       [-0.87350297]], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "batch_size = 1000\n",
    "n_batches = 10 #int(np.ceil(m/batch_size))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "#XT = tf.transpose(X)\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)            \n",
    "            sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "    best_theta = theta.eval()\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 5.09407\n",
      "Epoch 100 MSE = 0.659464\n",
      "Epoch 200 MSE = 0.577468\n",
      "Epoch 300 MSE = 0.563582\n",
      "Epoch 400 MSE = 0.554667\n",
      "Epoch 500 MSE = 0.547963\n",
      "Epoch 600 MSE = 0.542839\n",
      "Epoch 700 MSE = 0.5389\n",
      "Epoch 800 MSE = 0.535854\n",
      "Epoch 900 MSE = 0.533488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.06855249],\n",
       "       [ 0.88501078],\n",
       "       [ 0.14685963],\n",
       "       [-0.33703393],\n",
       "       [ 0.35024965],\n",
       "       [ 0.00500379],\n",
       "       [-0.04288518],\n",
       "       [-0.64297843],\n",
       "       [-0.61847723]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "#XT = tf.transpose(X)\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            save_path = saver.save(sess, \"./tmp/model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"./tmp/model_final.ckpt\")\n",
    "\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restore a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 0.533488\n",
      "Epoch 100 MSE = 0.53164\n",
      "Epoch 200 MSE = 0.530188\n",
      "Epoch 300 MSE = 0.529044\n",
      "Epoch 400 MSE = 0.528137\n",
      "Epoch 500 MSE = 0.527413\n",
      "Epoch 600 MSE = 0.526835\n",
      "Epoch 700 MSE = 0.526371\n",
      "Epoch 800 MSE = 0.525996\n",
      "Epoch 900 MSE = 0.525694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.06855249e+00],\n",
       "       [  8.59643519e-01],\n",
       "       [  1.28414184e-01],\n",
       "       [ -3.14709216e-01],\n",
       "       [  3.43048215e-01],\n",
       "       [ -1.37762446e-03],\n",
       "       [ -4.07838225e-02],\n",
       "       [ -8.01254332e-01],\n",
       "       [ -7.75039196e-01]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype=tf.float32, name=\"y\")\n",
    "#XT = tf.transpose(X)\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./tmp/model.ckpt\")\n",
    "    #sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            #save_path = saver.save(sess, \"./tmp/model.ckpt\")\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    #save_path = saver.save(sess, \"./tmp/model_final.ckpt\")\n",
    "\n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualing the Graph and Training Curves using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.65287\n",
      "Epoch 100 MSE = 0.489574\n",
      "Epoch 200 MSE = 0.536631\n",
      "Epoch 300 MSE = 0.563732\n",
      "Epoch 400 MSE = 0.531661\n",
      "Epoch 500 MSE = 0.561771\n",
      "Epoch 600 MSE = 0.530243\n",
      "Epoch 700 MSE = 0.515977\n",
      "Epoch 800 MSE = 0.570246\n",
      "Epoch 900 MSE = 0.478018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.06452680e+00],\n",
       "       [  8.25280368e-01],\n",
       "       [  1.19496971e-01],\n",
       "       [ -2.83477902e-01],\n",
       "       [  2.89164603e-01],\n",
       "       [  2.97480728e-05],\n",
       "       [ -3.97667922e-02],\n",
       "       [ -8.98564637e-01],\n",
       "       [ -8.69776428e-01]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01 \n",
    "batch_size = 1000\n",
    "n_batches = 10 #int(np.ceil(m/batch_size))\n",
    "\n",
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n+1,1],-1.0,1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)                        \n",
    "            if batch_index%10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y:y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y:y_batch})\n",
    "        if epoch%100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch, y: y_batch}))\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.close()    \n",
    "best_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1:<br>\n",
    "Epoch 0 MSE = 6.94011<br>\n",
    "Epoch 100 MSE = 0.48316<br>\n",
    "Epoch 200 MSE = 0.519101<br>\n",
    "Epoch 300 MSE = 0.487074<br>\n",
    "Epoch 400 MSE = 0.488232<br>\n",
    "Epoch 500 MSE = 0.522554<br>\n",
    "Epoch 600 MSE = 0.473014<br>\n",
    "Epoch 700 MSE = 0.514996<br>\n",
    "Epoch 800 MSE = 0.489359<br>\n",
    "Epoch 900 MSE = 0.603913<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open TensorBoard, do the following command at terminal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_modules\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = fetch_batch(epoch=0, batch_index=0, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    w_shape = (int(X.shape[1]), 1)#(int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X,w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "\n",
    "#n_features = n\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "output_summary = tf.summary.scalar('output', output)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #X_batch, y_batch = fetch_batch(epoch=0, batch_index=0, batch_size=100)\n",
    "    sess.run(output, feed_dict={X: X_batch})\n",
    "    #summary_str = output_summary.eval(feed_dict={X: X_batch})\n",
    "    #file_writer.add_summary(summary_str)\n",
    "    \n",
    "file_writer.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Scopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_name_scopes\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.shape[1]), 1)#(int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X,w), b, name=\"z\")\n",
    "        maximum = tf.maximum(z, 0., name=\"max\")\n",
    "        return maximum\n",
    "\n",
    "#n_features = n\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "#output_summary = tf.summary.scalar('output', output)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #X_batch, y_batch = fetch_batch(epoch=0, batch_index=0, batch_size=100)\n",
    "    sess.run(output, feed_dict={X: X_batch})\n",
    "    #summary_str = output_summary.eval(feed_dict={X: X_batch})\n",
    "    #file_writer.add_summary(summary_str)\n",
    "    \n",
    "file_writer.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_sv1\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_batch, y_batch = fetch_batch(epoch=0, batch_index=0, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        with tf.name_scope(\"relu\"):\n",
    "            w_shape = (int(X.shape[1]), 1)#(int(X.get_shape()[1]), 1)\n",
    "            w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "            b = tf.Variable(0.0, name=\"bias\")\n",
    "            z = tf.add(tf.matmul(X,w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "with tf.variable_scope(\"relu\"): \n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(output, feed_dict={X: X_batch})\n",
    "    \n",
    "file_writer.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of sharing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_sv2\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),initializer=tf.constant_initializer(0.0))\n",
    "#     with tf.variable_scope(\"relu\", reuse=True):\n",
    "#         threshold = tf.get_variable(\"threshold\")\n",
    "    with tf.name_scope(\"relu\"):\n",
    "        w_shape = (int(X.shape[1]), 1)#(int(X.get_shape()[1]), 1)\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name=\"bias\")\n",
    "        z = tf.add(tf.matmul(X,w), b, name=\"z\")\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n+1), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):    \n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(output, feed_dict={X: X_batch})\n",
    "    \n",
    "file_writer.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
